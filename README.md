# Project
We have trained, fine-tuned and played around with the existing Prithvi_vit_100 model on the fire_scar dataset. We Synced wandb to check for the accuracy scores and losses. Used the IoU metric to compare with the ground truth mask.

# Tuning 
Epochs trained - 50
model accuracy - 97.486
learning rate -  0.0003 

# Tools and Frameworks Used

Prithvi_ViT_100: Vision Transformer model architecture used for image classification.

Weights and Biases (wandb): Used for experiment tracking, visualizations, and logging.

Terra_torch library for building model.

Prithvi_ViT_100 Model Training and Parameter Tuning

# Hackathon Evaluation Details
Participants must provide the following:

Training Notebook:

A Jupyter Notebook to run the model training.
Include the trained model weights and necessary logs.
Ensure the notebook is easy to run for the judges.
Model Improvement Documentation:

A comprehensive list of attempts to improve model performance.
Include results for each attempt.
Judges will evaluate the level of effort, decision-making process, and results.
Performance Metrics Calculation:

Calculate Intersection over Union (IoU) as the performance metric.
See inference_terratorch.ipynb for details on testing the model.
Inference Notebook:

A final notebook to run model inference.
The test split will not be provided but will have the same format as the training/validation data.
Judges will use this notebook to calculate the IoU score, so ensure all steps are clearly shown.
The notebook will be run with a held-out set of data, so do not expect 100% accuracy.
TerraTorch Documentation:

Refer to the config_explainer.md file for more details. You need to understand the configuration details for potential model improvements.
Refer to the TerraTorch Quick Start documentation for more details on running model inference and configuration details.
We have trained, fine-tuned and played around with the existing Prithvi_vit_100 model on the fire_scar dataset, and successfully ended up with a accuProject
We have trained, fine-tuned and played around with the existing Prithvi_vit_100 model on the fire_scar dataset, and successfully ended up with a accuracy of 98.40. We Synced wandb to check for the accuracy scores and losses. 



# Tools and Frameworks Used

Prithvi_ViT_100: Vision Transformer model architecture used for image classification.

Weights and Biases (wandb): Used for experiment tracking, visualizations, and logging.

Terra_torch: Deep learning framework for building and training the model.

Prithvi_ViT_100 Model Training and Parameter Tuning

# Hackathon Evaluation Details
Participants must provide the following:

Training Notebook:

A Jupyter Notebook to run the model training.
Include the trained model weights and necessary logs.
Ensure the notebook is easy to run for the judges.
Model Improvement Documentation:

A comprehensive list of attempts to improve model performance.
Include results for each attempt.
Judges will evaluate the level of effort, decision-making process, and results.
Performance Metrics Calculation:

Calculate Intersection over Union (IoU) as the performance metric.
See inference_terratorch.ipynb for details on testing the model.
Inference Notebook:

A final notebook to run model inference.
The test split will not be provided but will have the same format as the training/validation data.
Judges will use this notebook to calculate the IoU score, so ensure all steps are clearly shown.
The notebook will be run with a held-out set of data, so do not expect 100% accuracy.
TerraTorch Documentation:

Refer to the config_explainer.md file for more details. You need to understand the configuration details for potential model improvements.
Refer to the TerraTorch Quick Start documentation for more details on running model inference and configuration details.
We have trained, fine-tuned and played around with the existing Prithvi_vit_100 model on the fire_scar dataset, and successfully ended up with a accuracy of 98.40. We Synced wandb to check for the accuracy scores and losses. 



# Tools and Frameworks Used

Prithvi_ViT_100: Vision Transformer model architecture used for image classification.

Weights and Biases (wandb): Used for experiment tracking, visualizations, and loggingracy of 98.40. We Synced wandb to check for the accuracy scores and losses. 



# Tools and Frameworks Used

Prithvi_ViT_100: Vision Transformer model architecture used for image classification.

Weights and Biases (wandb): Used for experiment tracking, visualizations, and logging.

Terra_torch: Deep learning framework for building and training the model.

Prithvi_ViT_100 Model Training and Parameter Tuning

# Hackathon Evaluation Details
Participants must provide the following:

Training Notebook:

A Jupyter Notebook to run the model training.
Include the trained model weights and necessary logs.
Ensure the notebook is easy to run for the judges.
Model Improvement Documentation:

A comprehensive list of attempts to improve model performance.
Include results for each attempt.
Judges will evaluate the level of effort, decision-making process, and results.
Performance Metrics Calculation:

Calculate Intersection over Union (IoU) as the performance metric.
See inference_terratorch.ipynb for details on testing the model.
Inference Notebook:

A final notebook to run model inference.
The test split will not be provided but will have the same format as the training/validation data.
Judges will use this notebook to calculate the IoU score, so ensure all steps are clearly shown.
The notebook will be run with a held-out set of data, so do not expect 100% accuracy.
TerraTorch Documentation:

Refer to the config_explainer.md file for more details. You need to understand the configuration details for potential model improvements.
Refer to the TerraTorch Quick Start documentation for more details on running model inference and configuration details.

# Metric
IoU Metric Calculation was used 

Formula: $$ IoU = \frac{True Positive}{True Positive + False Positive + False Negative} $$

 

# Metric
IoU Metric Calculation was used 

Formula: $$ IoU = \frac{True Positive}{True Positive + False Positive + False Negative} $$

 
